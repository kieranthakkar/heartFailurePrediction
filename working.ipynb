{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Failure Prediction\n",
    "#### Using Kaggle data to create a model for predicting mortality caused by Heart Failure.\n",
    "Creating a neural network (ANN) and comparing it to baseline models (SVM, kNN, LogisticRegression)\n",
    "\n",
    "Performance metrics: accuracy, precision, recall, F1-score, ROC curve, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "## standard modules\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "## pre-processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## modelling\n",
    "### baseline\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "### artificial neural network (ANN)\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "## cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "## performance metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data and preprocessing\n",
    "\n",
    "Data split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.833893</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>581.839465</td>\n",
       "      <td>0.41806</td>\n",
       "      <td>38.083612</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>263358.029264</td>\n",
       "      <td>1.39388</td>\n",
       "      <td>136.625418</td>\n",
       "      <td>0.648829</td>\n",
       "      <td>0.32107</td>\n",
       "      <td>130.26087</td>\n",
       "      <td>0.32107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25100.000000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7861.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>850000.000000</td>\n",
       "      <td>9.40000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>285.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age     anaemia  creatinine_phosphokinase   diabetes  \\\n",
       "count  299.000000  299.000000                299.000000  299.00000   \n",
       "mean    60.833893    0.431438                581.839465    0.41806   \n",
       "min     40.000000    0.000000                 23.000000    0.00000   \n",
       "max     95.000000    1.000000               7861.000000    1.00000   \n",
       "\n",
       "       ejection_fraction  high_blood_pressure      platelets  \\\n",
       "count         299.000000           299.000000     299.000000   \n",
       "mean           38.083612             0.351171  263358.029264   \n",
       "min            14.000000             0.000000   25100.000000   \n",
       "max            80.000000             1.000000  850000.000000   \n",
       "\n",
       "       serum_creatinine  serum_sodium         sex    smoking       time  \\\n",
       "count         299.00000    299.000000  299.000000  299.00000  299.00000   \n",
       "mean            1.39388    136.625418    0.648829    0.32107  130.26087   \n",
       "min             0.50000    113.000000    0.000000    0.00000    4.00000   \n",
       "max             9.40000    148.000000    1.000000    1.00000  285.00000   \n",
       "\n",
       "       DEATH_EVENT  \n",
       "count    299.00000  \n",
       "mean       0.32107  \n",
       "min        0.00000  \n",
       "max        1.00000  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "df = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")\n",
    "described = df.describe().drop(axis=0, index=[\"std\",\"25%\",\"50%\",\"75%\"])\n",
    "described"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note the dataset has 12 features contributing to the DEATH_EVENT. No columns are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.DEATH_EVENT.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3179916317991632"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = y_train.mean()\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise\n",
    "ann = Sequential()\n",
    "\n",
    "# input layer\n",
    "ann.add(Dense(units=16, kernel_initializer=\"uniform\", activation=\"relu\", input_dim=12))\n",
    "\n",
    "# hidden layers w/ regularisation\n",
    "ann.add(Dense(units=8, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "ann.add(Dropout(0.25))\n",
    "ann.add(Dense(units=8, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "ann.add(Dropout(0.5))\n",
    "\n",
    "# output layer\n",
    "ann.add(Dense(units=1, kernel_initializer=\"uniform\", activation=\"sigmoid\")) # units = 1 because this is binary classification (0 or 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the network\n",
    "ann.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 40ms/step - loss: 0.6928 - accuracy: 0.6257 - val_loss: 0.6919 - val_accuracy: 0.7000\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6916 - accuracy: 0.6760 - val_loss: 0.6908 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6907 - accuracy: 0.6760 - val_loss: 0.6896 - val_accuracy: 0.7000\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.6760 - val_loss: 0.6885 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6886 - accuracy: 0.6760 - val_loss: 0.6872 - val_accuracy: 0.7000\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6875 - accuracy: 0.6760 - val_loss: 0.6858 - val_accuracy: 0.7000\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6862 - accuracy: 0.6760 - val_loss: 0.6844 - val_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6848 - accuracy: 0.6760 - val_loss: 0.6828 - val_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6835 - accuracy: 0.6760 - val_loss: 0.6811 - val_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6818 - accuracy: 0.6760 - val_loss: 0.6791 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6802 - accuracy: 0.6760 - val_loss: 0.6769 - val_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6788 - accuracy: 0.6760 - val_loss: 0.6744 - val_accuracy: 0.7000\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6748 - accuracy: 0.6760 - val_loss: 0.6713 - val_accuracy: 0.7000\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6706 - accuracy: 0.6760 - val_loss: 0.6675 - val_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6648 - accuracy: 0.6760 - val_loss: 0.6628 - val_accuracy: 0.7000\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6628 - accuracy: 0.6760 - val_loss: 0.6569 - val_accuracy: 0.7000\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6546 - accuracy: 0.6760 - val_loss: 0.6502 - val_accuracy: 0.7000\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6517 - accuracy: 0.6760 - val_loss: 0.6426 - val_accuracy: 0.7000\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6387 - accuracy: 0.6760 - val_loss: 0.6338 - val_accuracy: 0.7000\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6319 - accuracy: 0.6872 - val_loss: 0.6240 - val_accuracy: 0.7167\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6166 - accuracy: 0.6872 - val_loss: 0.6122 - val_accuracy: 0.7333\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6190 - accuracy: 0.7430 - val_loss: 0.5996 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5986 - accuracy: 0.7542 - val_loss: 0.5858 - val_accuracy: 0.7167\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5775 - accuracy: 0.7821 - val_loss: 0.5708 - val_accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5501 - accuracy: 0.7933 - val_loss: 0.5536 - val_accuracy: 0.7667\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5415 - accuracy: 0.8101 - val_loss: 0.5360 - val_accuracy: 0.7667\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5324 - accuracy: 0.8492 - val_loss: 0.5190 - val_accuracy: 0.7667\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5081 - accuracy: 0.8268 - val_loss: 0.5038 - val_accuracy: 0.7833\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5011 - accuracy: 0.8436 - val_loss: 0.4902 - val_accuracy: 0.7667\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4925 - accuracy: 0.8324 - val_loss: 0.4781 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4878 - accuracy: 0.8547 - val_loss: 0.4678 - val_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4857 - accuracy: 0.8492 - val_loss: 0.4590 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4887 - accuracy: 0.8268 - val_loss: 0.4531 - val_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4538 - accuracy: 0.8492 - val_loss: 0.4491 - val_accuracy: 0.7833\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4364 - accuracy: 0.8715 - val_loss: 0.4453 - val_accuracy: 0.7833\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4566 - accuracy: 0.8380 - val_loss: 0.4447 - val_accuracy: 0.7833\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4390 - accuracy: 0.8715 - val_loss: 0.4431 - val_accuracy: 0.7833\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4492 - accuracy: 0.8436 - val_loss: 0.4404 - val_accuracy: 0.7833\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4526 - accuracy: 0.8715 - val_loss: 0.4389 - val_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4405 - accuracy: 0.8603 - val_loss: 0.4389 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4504 - accuracy: 0.8380 - val_loss: 0.4394 - val_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4577 - accuracy: 0.8659 - val_loss: 0.4412 - val_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4544 - accuracy: 0.8492 - val_loss: 0.4434 - val_accuracy: 0.7833\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4775 - accuracy: 0.8268 - val_loss: 0.4447 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4244 - accuracy: 0.8603 - val_loss: 0.4433 - val_accuracy: 0.7833\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4200 - accuracy: 0.8547 - val_loss: 0.4429 - val_accuracy: 0.7833\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.8380 - val_loss: 0.4424 - val_accuracy: 0.7833\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4042 - accuracy: 0.8492 - val_loss: 0.4413 - val_accuracy: 0.7833\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4845 - accuracy: 0.8324 - val_loss: 0.4416 - val_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4631 - accuracy: 0.8603 - val_loss: 0.4422 - val_accuracy: 0.7833\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3965 - accuracy: 0.8603 - val_loss: 0.4413 - val_accuracy: 0.7833\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4177 - accuracy: 0.8603 - val_loss: 0.4402 - val_accuracy: 0.7833\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4077 - accuracy: 0.8547 - val_loss: 0.4393 - val_accuracy: 0.7833\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4173 - accuracy: 0.8603 - val_loss: 0.4397 - val_accuracy: 0.7833\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4135 - accuracy: 0.8659 - val_loss: 0.4417 - val_accuracy: 0.7833\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4210 - accuracy: 0.8659 - val_loss: 0.4432 - val_accuracy: 0.7833\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4071 - accuracy: 0.8492 - val_loss: 0.4443 - val_accuracy: 0.7833\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3959 - accuracy: 0.8547 - val_loss: 0.4464 - val_accuracy: 0.7667\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8883 - val_loss: 0.4465 - val_accuracy: 0.7667\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.8547 - val_loss: 0.4466 - val_accuracy: 0.7667\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3964 - accuracy: 0.8380 - val_loss: 0.4451 - val_accuracy: 0.7667\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3690 - accuracy: 0.8715 - val_loss: 0.4442 - val_accuracy: 0.7833\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4035 - accuracy: 0.8492 - val_loss: 0.4448 - val_accuracy: 0.7667\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4590 - accuracy: 0.8547 - val_loss: 0.4457 - val_accuracy: 0.7667\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3698 - accuracy: 0.8659 - val_loss: 0.4445 - val_accuracy: 0.7833\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4020 - accuracy: 0.8715 - val_loss: 0.4422 - val_accuracy: 0.7833\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4228 - accuracy: 0.8547 - val_loss: 0.4424 - val_accuracy: 0.7833\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8771 - val_loss: 0.4443 - val_accuracy: 0.7833\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3810 - accuracy: 0.8492 - val_loss: 0.4458 - val_accuracy: 0.7833\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.8771 - val_loss: 0.4462 - val_accuracy: 0.7833\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4445 - accuracy: 0.8547 - val_loss: 0.4472 - val_accuracy: 0.7833\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8492 - val_loss: 0.4488 - val_accuracy: 0.7667\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3786 - accuracy: 0.8883 - val_loss: 0.4515 - val_accuracy: 0.7667\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4148 - accuracy: 0.8547 - val_loss: 0.4509 - val_accuracy: 0.7667\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4112 - accuracy: 0.8659 - val_loss: 0.4517 - val_accuracy: 0.7667\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3922 - accuracy: 0.8715 - val_loss: 0.4539 - val_accuracy: 0.7667\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4046 - accuracy: 0.8659 - val_loss: 0.4541 - val_accuracy: 0.7667\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3716 - accuracy: 0.8715 - val_loss: 0.4544 - val_accuracy: 0.7667\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8771 - val_loss: 0.4575 - val_accuracy: 0.7667\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3884 - accuracy: 0.8659 - val_loss: 0.4586 - val_accuracy: 0.7667\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3454 - accuracy: 0.8715 - val_loss: 0.4596 - val_accuracy: 0.7667\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3903 - accuracy: 0.8827 - val_loss: 0.4610 - val_accuracy: 0.7667\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3519 - accuracy: 0.8715 - val_loss: 0.4614 - val_accuracy: 0.7833\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3840 - accuracy: 0.8715 - val_loss: 0.4621 - val_accuracy: 0.7667\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3436 - accuracy: 0.8994 - val_loss: 0.4622 - val_accuracy: 0.7667\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3942 - accuracy: 0.8883 - val_loss: 0.4632 - val_accuracy: 0.7667\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3819 - accuracy: 0.8827 - val_loss: 0.4601 - val_accuracy: 0.7667\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3751 - accuracy: 0.8659 - val_loss: 0.4577 - val_accuracy: 0.7833\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3805 - accuracy: 0.8827 - val_loss: 0.4570 - val_accuracy: 0.8000\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3503 - accuracy: 0.9050 - val_loss: 0.4581 - val_accuracy: 0.8000\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3849 - accuracy: 0.8771 - val_loss: 0.4617 - val_accuracy: 0.7833\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4116 - accuracy: 0.8715 - val_loss: 0.4638 - val_accuracy: 0.7833\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3913 - accuracy: 0.8603 - val_loss: 0.4644 - val_accuracy: 0.8000\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3534 - accuracy: 0.8659 - val_loss: 0.4636 - val_accuracy: 0.8000\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8715 - val_loss: 0.4620 - val_accuracy: 0.8000\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4029 - accuracy: 0.8771 - val_loss: 0.4599 - val_accuracy: 0.8000\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3347 - accuracy: 0.8883 - val_loss: 0.4597 - val_accuracy: 0.8000\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8827 - val_loss: 0.4594 - val_accuracy: 0.8000\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3979 - accuracy: 0.8827 - val_loss: 0.4582 - val_accuracy: 0.8000\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3840 - accuracy: 0.8603 - val_loss: 0.4570 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# train the ANN\n",
    "history = ann.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validation_accuracy is: 76.42%\n"
     ]
    }
   ],
   "source": [
    "val_accuracy = np.mean(history.history['val_accuracy'])\n",
    "print(\"\\n%s: %.2f%%\" % ('validation_accuracy is', val_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ann_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ann_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "ann.save(\"ann_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions\n",
    "ann_pred = ann.predict(X_test)\n",
    "ann_pred = np.where(ann_pred>threshold, 1, 0)\n",
    "ann_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting the confusion matrix\n",
    "plt.subplots(figsize=(6,5))\n",
    "cf_matrix = confusion_matrix(y_test, ann_pred)\n",
    "sns.heatmap(cf_matrix, annot = True, annot_kws = {'size':25}, square=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
